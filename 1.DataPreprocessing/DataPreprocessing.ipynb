{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec615231",
   "metadata": {},
   "source": [
    "<img src=\"./assets/uca.png\" alt=\"Tech Logo\" align=\"center\" height=\"800\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c5313",
   "metadata": {},
   "source": [
    "<h1 align=\"left\" style=\"color:#000051;font-size: 30px\">TP : Classifiez des √©motions vocales avec du deep learning</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a15b35",
   "metadata": {},
   "source": [
    "Pour ce TP, vous impl√©menterez un classifieur √† base de r√©seau de neurones sur des donn√©es combinant les jeux de donn√©es RAVDESS et TESS avec la librairie keras. \n",
    "Repartez de ce notebook Jupyter qui passe en revue chaque partie du TP pour pr√©senter des preuves et une analyse de vos r√©sultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206adde7",
   "metadata": {},
   "source": [
    "<h1 align=\"left\" style=\"color:#000051;font-size: 25px\">Partie 1 : Pr√©-traitement des donn√©es</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cbfd6c",
   "metadata": {},
   "source": [
    "Dans cette partie nous nous attacherons principalement √† pr√©-traiter les donn√©es audio du jeu de donn√©es, c'est-√†-dire pr√©parer les donn√©es en vue de les utiliser comme entr√©es du mod√®le de deep learning que nous construirons par la suite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26783561",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: left; color:#20a08d; font-size: 25px\"><span>üíæ <strong>A propos des jeux de donn√©es </strong></span></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ffd4da",
   "metadata": {},
   "source": [
    "Pour ce TP, nous utiliserons 2 jeux de donn√©es\n",
    "\n",
    "- **RAVDESS : Ryerson Audio-Visual Database of Emotional Speech and Song**\n",
    "https://zenodo.org/record/1188976#.X4sE0tDXKUl\n",
    "  - RAVDESS a √©t√© enregistr√©e avec 24 acteurs professionnels (12 femmes, 12 hommes), pronon√ßant deux phrases lexicalement identiques avec un accent nord-am√©ricain neutre. Chaque phrase est prononc√©e avec deux niveaux d'intensit√© √©motionnelle (normal, fort).\n",
    "  - **1440 fichiers** = 24 acteurs x 60 fichiers audio par acteur\n",
    "  - **8 √©motions** (neutre, calme, joie, tristesse, col√®re, peur, d√©gout, surprise).\n",
    "\n",
    "\n",
    "\n",
    "- **TESS : Toronto Emotional Speech Set**\n",
    "https://tspace.library.utoronto.ca/handle/1807/24487\n",
    "  - Ces donn√©es ont √©t√© enregistr√©es par le Northwestern University Auditory. Un ensemble de 200 mots cibles ont √©t√© prononc√©s dans la phrase \"Dites le mot _____\" par deux actrices (√¢g√©es de 26 et 64 ans) et des enregistrements ont √©t√© r√©alis√©s lorsque ces phrases ont √©t√© prononc√©es avec chacune des sept √©motions d√©crites ci-dessous.\n",
    "Les deux actrices ont √©t√© recrut√©es dans la r√©gion de Toronto. Les deux actrices parlent l'anglais comme premi√®re langue, ont fait des √©tudes universitaires et ont une formation musicale.\n",
    "  - **2800 fichiers** = 2 acteurs x 200 phrases x 7 √©motions\n",
    "  - **7 √©motions** (neutre, joie, tristesse, col√®re, peur, d√©go√ªt, surprise)('calme' ne fait pas partie de cette BD) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d28a911",
   "metadata": {},
   "source": [
    "Pour ce TP, pour des consid√©rations de volume de donn√©es, nous n'avons retenu que 4 des √©motions:\n",
    "- **neutre**\n",
    "- **joie**\n",
    "- **tristesse**\n",
    "- **col√®re**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527d7c71",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: left; color:#20a08d; font-size: 25px\"><span>üì• <strong>1. Import des librairies </strong></span></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff0256",
   "metadata": {},
   "source": [
    "Si vous avez besoin d'installer des libraires Python pour ce TP, d√©commentez et ex√©cutez la cellule ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d9803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install numpy\n",
    "#!pip3 install pydub\n",
    "#!pip3 install librosa\n",
    "#!pip3 install noisereduce\n",
    "#!pip3 install matplotlib\n",
    "#!pip3 install IPython\n",
    "#pip3 install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from pydub import AudioSegment, effects\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile\n",
    "import noisereduce as nr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from librosa import display   \n",
    "import IPython.display as ipd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac285c10",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: left; color:#20a08d; font-size: 25px\"><span>üîé <strong>2. Exploration du jeu de donn√©es </strong></span></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cf63a1",
   "metadata": {},
   "source": [
    "Avant de commencer √† pr√©traiter les donn√©es, faisons-nous une id√©e de ce √† quoi ressemble les donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2501f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset folders\n",
    "TESS_DATASET_FOLDER = \"./dataset/tess\"\n",
    "RAVDESS_DATASET_FOLDER = \"./dataset/ravdess\"\n",
    "\n",
    "# Example files\n",
    "TESS_FILE_EXAMPLE = \"./dataset/tess/YAF_goose_sad.wav\"\n",
    "RAVDESS_FILE_EXAMPLE = \"./dataset/ravdess/03-01-01-01-01-01-02.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b6c44c",
   "metadata": {},
   "source": [
    "Nous pouvons utiliser ici IPython pour √©couter le contenu audio des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5161fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecoute de deux fichiers examples\n",
    "rawsound_tess = AudioSegment.from_file(TESS_FILE_EXAMPLE)\n",
    "rawsound_ravdess = AudioSegment.from_file(RAVDESS_FILE_EXAMPLE)\n",
    "\n",
    "ipd.display(rawsound_tess)\n",
    "ipd.display(rawsound_ravdess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a1312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_waveform(folder):\n",
    "    \n",
    "    '''\n",
    "    Fonction pour afficher les formes d'ondes (waveform) de 5 fichiers audio al√©atoirement choisis dans un r√©pertoire\n",
    "\n",
    "            Parameters:\n",
    "                    folder (str): Chaine de caract√®re repr√©sentant le chemin d'acc√®s au r√©pertoire contenant les fichiers \n",
    "\n",
    "            Returns:\n",
    "                    Rien : affiche les formes d'ondes\n",
    "                    \n",
    "\n",
    "    '''\n",
    "    # Affichage des 5 fichiers audio al√©atoirement choisis dans le jeu de donn√©es TESS\n",
    "\n",
    "    # R√©cup√©ration de la liste des fichiers\n",
    "    tess_files_list = os.listdir(folder)\n",
    "    tess_files_list = [os.path.join(folder, file) for file in tess_files_list]\n",
    "\n",
    "    # Affichage\n",
    "    plt.figure(figsize=(18, 3))\n",
    "    for i in range(5):\n",
    "        random_file = random.choice(tess_files_list)\n",
    "        rawsound = AudioSegment.from_file(random_file)\n",
    "        x, sr = librosa.load(random_file, sr = None)\n",
    "\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        #plt.figure(figsize=(12,1))\n",
    "        librosa.display.waveplot(x, sr)\n",
    "        plt.title(os.path.basename(random_file))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_waveform(folder=TESS_DATASET_FOLDER)\n",
    "display_waveform(folder=RAVDESS_DATASET_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b956aaa",
   "metadata": {},
   "source": [
    "La forme d'onde repr√©sente la valeur de chaque √©chantillon audio en fonction du temps. Il s'agit juste d'une courbe repr√©sentant chaque √©chantillon en fonction du temps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2290b8",
   "metadata": {},
   "source": [
    "<img src=\"./assets/waveform.webp\" alt=\"Tech Logo\" align=\"center\" height=\"1280\" width=\"960\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08df0a7e",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: left; color:#20a08d; font-size: 25px\"><span>\n",
    "üóÉÔ∏è <strong>3. Pr√©-traitement du jeu de donn√©es</strong></span></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448dc827",
   "metadata": {},
   "source": [
    "Le sch√©ma ci-dessous pr√©sente la chaine compl√®te de pr√©-traitement √† r√©aliser pour pr√©-traiter et extraire des caract√©ristiques de notre jeu de donn√©es.\n",
    "\n",
    "Nous nous interessons ici dans un premier temps √† la partie pr√©-traitement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d791d5",
   "metadata": {},
   "source": [
    "<img src=\"./assets/preprocess.jpg\" alt=\"Tech Logo\" align=\"center\" height=\"1280\" width=\"960\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dea3f0",
   "metadata": {},
   "source": [
    "Le pr√©-traitement des audios n√©cessite 3 types de traitements:\n",
    "1. **Extraction de la classe d'appartenance**\n",
    "\n",
    "     * RAVDESS : Dans le jeu de donn√©es RAVDESS, le nom du fichier contient un nombre qui repr√©sente l'√©motion exprim√©e dans le fichier audio. Un fichier RAVDESS consiste en un identifiant num√©rique en 7 parties (par exemple, 03-01-06-01-02-01-12.wav). Les deux premi√®res parties √©tant fixes, le fichier peut √™tre repr√©sent√© comme suit : 03-01-X-X-X-X-X.wav. Les √©motions sont indiqu√©es dans la 3√®me partie (Le 1er 'X') \n",
    "     * TESS : le nom de fichier contient une repr√©sentation directe d'une √©motion. Les noms de fichier TESS sont compos√©s de 3 parties, l'√©motion √©tant indiqu√©e dans la 3√®me partie. Par exemple, dans le fichier \"YAF_youth_happy.wav\",  \"happy\".\n",
    "\n",
    "\n",
    "2. **Fr√©quence d'√©chantillonnage** : nombre d'√©chantillons audio par seconde. La base de donn√©es RAVDESS a √©t√© enregistr√©e en 48 kHz et la base de donn√©es TESS a √©t√© enregistr√©e en 22,5 kHz.\n",
    "\n",
    "\n",
    "3. **La s√©quence de pr√©-traitement** d'un fichier audio contient les traitements suivants :\n",
    "\n",
    "\n",
    "* Objet 'AudioSegment' : L'audio est charg√© dans un objet 'AudioSegment' par la biblioth√®que pydub\n",
    "* Normalisation : Chaque objet 'AudioSegment' est normalis√© √† + 5,0 dBFS.\n",
    "\n",
    "* Conversion en tableau Numpy : La transformation de l'objet AudioSegment en un tableau d'√©chantillons est cruciale pour le reste du pr√©traitement.\n",
    "* Suppression des silences : Les zones de silences, souvent au d√©but et √† la fin de l'extrait sonore, sont supprim√©es pour se d√©barrasser des donn√©es inutiles.\n",
    "* Padding : Afin d'avoir des audios de la m√™me taille, il est n√©cessaire de faire du padding sur chaque fichier audio afin qu'ils aient la m√™me longueur. Ceci est crucial pour utiliser les donn√©es dans un mod√®le de deep learning\n",
    "* R√©duction de bruit : la r√©duction du bruit permet de supprimer d'√©ventuelles bruits, c'est-√†-dire des donn√©es qui ne sont pas de la parole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb36688f",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: left; color:#20a08d; font-size: 20px\"><span>üóÉÔ∏è <strong>3.1 Pr√©-traitement unitaire </strong></span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb963f",
   "metadata": {},
   "source": [
    "Dans cette partie, nous d√©veloppons pas √† pas chacun des pr√©-traitements necessaires. Chaque pr√©-traitement sera cod√© dans une fonction et test√© sur un fichier exemple.\n",
    "Afin de s'assurer que les traitements sont bien r√©alis√©s, il faudra visualiser et √©couter le fichier r√©sultant du pr√©-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b308b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin d'acc√®s au fichier exemple\n",
    "RAVDESS_FILE_EXAMPLE = \"./dataset/ravdess/03-01-01-01-01-01-02.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c778840",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: left; color:#20a08d; font-size: 15px\"><span>üóÉÔ∏è <strong>3.1.0 Visualisation et √©coute du fichier exemple</strong></span></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75bd499",
   "metadata": {},
   "source": [
    "La fonction ci-dessous permet d'afficher la forme d'onde et la barre d'√©coute d'un fichier audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24454a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_waveform(audio_array, sampling_rate, display_audio=True):\n",
    "    \n",
    "    '''\n",
    "    Fonction pour afficher la forme d'onde (waveform) d'un flux audio\n",
    "\n",
    "            Parameters:\n",
    "                    audio_array (Numpy array): Matrice de nombres de flottants repr√©sentant les √©chantillons audio du fichier audio\n",
    "                    sampling_rate (int): Valeur enti√®re repr√©sentant la fr√©quence d'√©chantillonnage du fichier audio\n",
    "                    display_audio(bool) : bool√©en indiquant si la barre d'√©coute du fichier audio devait √™tre affich√©e ou non\n",
    "\n",
    "\n",
    "            Returns:\n",
    "                    Rien : affiche la forme d'ondes et/ou la barre d'√©coute\n",
    "                    \n",
    "\n",
    "    '''\n",
    "\n",
    "    plt.figure(figsize=(12,1))\n",
    "    librosa.display.waveplot(audio_array, sampling_rate)\n",
    "    plt.title(\"Audio waveform\")\n",
    "    \n",
    "    if display_audio:\n",
    "        max_value = audio_array.max()\n",
    "        # Les fichiers wav avec des √©chantillons en format float32 doivent √™tre entre +1 et -1\n",
    "        # Si ce n'est pas le cas, il faut normaliser !\n",
    "        if max_value > 1:\n",
    "            audio_array = audio_array/max_value\n",
    "        \n",
    "        # Enregistrement d'un fichier temporaire    \n",
    "        wavfile.write(filename=\"./tmp.wav\", rate=sampling_rate, data=audio_array)\n",
    "        \n",
    "        # Affichage de l'audio pour playback        \n",
    "        rawsound = AudioSegment.from_wav(\"./tmp.wav\")\n",
    "        ipd.display(rawsound)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae181d47",
   "metadata": {},
   "source": [
    "Appliquons cette fonction pour visualiser la forme d'onde et ecouter le contenu du fichier exemple **RAVDESS_FILE_EXAMPLE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c1d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_array, sampling_rate = librosa.load(RAVDESS_FILE_EXAMPLE, sr = None)\n",
    "visualize_waveform(audio_array=audio_array, sampling_rate=sampling_rate, display_audio=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f021b9c",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: left; color:#20a08d; font-size: 15px\"><span>üóÉÔ∏è <strong>3.1.1 Instanciation de l'objet AudioSegment</strong></span></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68e726c",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code permettant d'instancier un objet AudioSegment √† partir du fichier exemple <strong>RAVDESS_FILE_EXAMPLE</strong> </span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a97634",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#ec8f1a\"><span>üìö  Working with wav files in Python using Pydub : </span><a href=\"https://www.geeksforgeeks.org/working-with-wav-files-in-python-using-pydub/\">https://www.geeksforgeeks.org/working-with-wav-files-in-python-using-pydub/</a></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d104e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75761ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68b33d45",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: left; color:#20a08d; font-size: 15px\"><span>üóÉÔ∏è <strong>3.1.2 Normalisation de volume et conversion en tableau numpy array</strong></span></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a13a68",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code dans la fonction  <strong>normalize_audio</strong> permettant d'ajouter 5 dBFS √† un contenu sonore, puis appelez cette fonction sur le fichier exemple <strong>RAVDESS_FILE_EXAMPLE</strong> </span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86495f94",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#ec8f1a\"><span>üìö  Introduction to\n",
    "PyDub : </span> <a href=\"https://s3.amazonaws.com/assets.datacamp.com/production/course_17718/slides/chapter3.pdf\">https://s3.amazonaws.com/assets.datacamp.com/production/course_17718/slides/chapter3.pdf</a></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ea541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import effects\n",
    "\n",
    "def normalize_audio(audio_segment):\n",
    "    \n",
    "    '''\n",
    "    Fonction pour rajouter 5 dBFS au volume du fichier audio\n",
    "\n",
    "            Parameters:\n",
    "                    audio_segment (Objet AudioSegment de pydub): Objet AudioSegment repr√©sentant le fichier audio √† normaliser\n",
    "\n",
    "            Returns:\n",
    "                    normalized_array (Numpy array) : Matrice de nombres repr√©sentant les √©chantillons du fichier audio apr√®s application du traitement\n",
    "                    \n",
    "\n",
    "    '''\n",
    "        \n",
    "\n",
    "    return normalized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cddc008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dff6ced7",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code permettant d'√©couter  et de visualiser la forme d'onde du flux audio r√©sultant </span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da6eb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ace1b504",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#7a0f43\"><span>‚ùì En observant la forme d'onde obtenue et en la comparant √† celle du fichier d'origine, quel effet a eu ce pr√©-traitement sur le flux audio du fichier  ?</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1991fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "620c944f",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: left; color:#20a08d; font-size: 15px\"><span>üóÉÔ∏è <strong>3.1.3 Suppression des silences</strong></span></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469cbb29",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code dans la fonction  <strong>remove_silence_from_audio</strong> permettant de supprimer les silences d'un contenu sonore, puis appelez cette fonction sur la matrice d'√©chantillon obtenue √† l'√©tape pr√©c√©dente </span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aa55c7",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#ec8f1a\"><span>üìö  librosa.effects.trim : </span> <a href=\"https://librosa.org/doc/main/generated/librosa.effects.trim.html\">https://librosa.org/doc/main/generated/librosa.effects.trim.html</a></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd69400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa import effects\n",
    "\n",
    "def remove_silence_from_audio(audio_array):\n",
    "    \n",
    "    '''\n",
    "    Fonction permettant de supprimer les silences d'un fichier audio\n",
    "\n",
    "            Parameters:\n",
    "                    audio_array (Numpy array): Matrice de nombres repr√©sentant les √©chantillons du fichier audio sur lequel appliquer la suppression de silences\n",
    "\n",
    "            Returns:\n",
    "                    silenced_array (Numpy array) : Matrice de nombres repr√©sentant les √©chantillons du fichier audio apr√®s application du traitement\n",
    "                    \n",
    "\n",
    "    '''\n",
    "    \n",
    "    return silenced_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfa394b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc49b8d2",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code permettant d'√©couter  et de visualiser la forme d'onde du flux audio r√©sultant </span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e0248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73c7e910",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#7a0f43\"><span>‚ùì En observant la forme d'onde obtenue et en la comparant √† celle obtenue √† l'√©tape pr√©c√©dente, quel effet a eu ce pr√©-traitement sur le flux audio ?</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8126b21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b70f8fd",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: left; color:#20a08d; font-size: 15px\"><span>üóÉÔ∏è <strong>3.1.4 Egalisation des longueurs </strong></span></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9cff49",
   "metadata": {},
   "source": [
    "Ici, nous voulons uniformiser les donn√©es en entr√©e du mod√®le afin qu'elles aient toute la m√™me longueur. Nous faisons arbitrairement le choix d'avoir des donn√©es en entr√©e du mod√®le correspondant √† 2 secondes de fichier audio. Mais selon que le fichier audio appartienne au dataset TESS ou RAVDESS, 2 secondes ne correspondent pas au m√™me nombre d'√©chantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd28091",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SECONDS = 2\n",
    "SR_TESS = 22500\n",
    "SR_RAVDESS = 48000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c02fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SAMPLES_RAVDESS = MAX_SECONDS * SR_RAVDESS\n",
    "MAX_SAMPLES_TESS = MAX_SECONDS * SR_TESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b815c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SAMPLES = np.max([MAX_SAMPLES_RAVDESS, MAX_SAMPLES_TESS])\n",
    "MAX_SAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dfc776",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code dans la fonction  <strong>length_equalization_audio</strong> permettant de ramener chaque matrice d'√©chantillons audio √† une longueur de MAX_SAMPLES (si les audios sont plus longues que 96000 √©chantillons, les couper pour les ramener √† 96000, si les audio sont plus courtes que 96000 √©chantillons, rajouter des 0 pour les ramener √† 96000 √©chantillons), puis appelez cette fonction sur la matrice d'√©chantillon obtenue √† l'√©tape pr√©c√©dente </span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3dfb2e",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#ec8f1a\"><span>üìö  numpy.pad : </span> <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.pad.html\">https://numpy.org/doc/stable/reference/generated/numpy.pad.html</a></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e759b197",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#ec8f1a\"><span>üìö  numpy.pad() function in Python : </span> <a href=\"https://www.geeksforgeeks.org/numpy-pad-function-in-python/\">https://www.geeksforgeeks.org/numpy-pad-function-in-python/</a></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433bda27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import pad\n",
    "\n",
    "def length_equalization_audio(audio_array, max_length=MAX_SAMPLES):\n",
    "    \n",
    "    '''\n",
    "    Fonction permettant de normaliser la longueur des √©chantillons d'un fichier audio\n",
    "\n",
    "            Parameters:\n",
    "                    audio_array (Numpy array): Matrice de nombres repr√©sentant les √©chantillons du fichier audio sur lequel appliquer l'√©galisation des longueurs\n",
    "                    max_length (int) : Nombre entier repr√©sentant la longueur en termes de nombre d'√©chantillons √† avoir\n",
    "\n",
    "            Returns:\n",
    "                    padded_array (Numpy array) : Matrice de nombres repr√©sentant les √©chantillons du fichier audio de longueur max_length\n",
    "                    \n",
    "\n",
    "    '''\n",
    "        \n",
    "\n",
    "    return padded_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a1df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7d1610f",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code permettant d'√©couter  et de visualiser la forme d'onde du flux audio r√©sultant </span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a63cfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c34235d",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#7a0f43\"><span>‚ùì En observant la forme d'onde obtenue et en la comparant √† celle obtenue √† l'√©tape pr√©c√©dente, quel effet a eu ce pr√©-traitement sur le flux audio ?</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6613a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f05e9b37",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: left; color:#20a08d; font-size: 15px\"><span>üóÉÔ∏è <strong>3.1.5 Suppression du bruit</strong></span></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb01b5d0",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code dans la fonction  <strong>noise_reduction_from_audio</strong> permettant de r√©duire le bruit dans chaque matrice d'√©chantillons audio, puis appelez cette fonction sur la matrice d'√©chantillon obtenue √† l'√©tape pr√©c√©dente </span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5d4ae1",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#ec8f1a\"><span>üìö  noisereduce : </span> <a href=\"https://github.com/timsainb/noisereduce#simplest-usage\">https://github.com/timsainb/noisereduce#simplest-usage</a></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4e331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import noisereduce as nr\n",
    "\n",
    "def noise_reduction_from_audio(audio_array, sampling_rate):\n",
    "    '''\n",
    "    Fonction permettant de supprimer le bruit d'un fichier audio\n",
    "\n",
    "            Parameters:\n",
    "                    audio_array (Numpy array): Matrice de nombres repr√©sentant les √©chantillons du fichier audio sur lequel appliquer la r√©duction de bruit\n",
    "                    sampling_rate (int) : Nombre entier repr√©sentant la fr√©quence d'√©chantillonnage du fichier audio\n",
    "\n",
    "            Returns:\n",
    "                    noise_reduced_array (Numpy array) : Matrice de nombres repr√©sentant les √©chantillons du fichier audio apr√®s r√©duction du bruit\n",
    "                    \n",
    "\n",
    "    '''\n",
    "        \n",
    "    return noise_reduced_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f5db1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a950df3",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code permettant d'√©couter  et de visualiser la forme d'onde du flux audio r√©sultant </span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac527c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "531ca29f",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: left; color:#20a08d; font-size: 20px\"><span>üóÉÔ∏è <strong>3.2 Pr√©-traitement unifi√© </strong></span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb8f98",
   "metadata": {},
   "source": [
    "Nous allons maintenant cr√©er une fonction de pr√©-traitement globale, qui rassemble l'ensemble des pr√©-traitements pr√©cedemment d√©velopp√©s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310bd14e",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code dans la fonction  <strong>preprocess_audio</strong> permettant d'appliquer toutes les op√©rations de pr√©-traitement pr√©c√©demment d√©velopp√©es sur un fichier audio, puis appelez cette fonction sur le fichier audio exemple <strong>RAVDESS_FILE_EXAMPLE</strong></span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67f186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(audio_filename, sampling_rate):\n",
    "    \n",
    "    '''\n",
    "    Fonction permettant d'appliquer toutes les op√©rations de pr√©-traitement sur un fichier audio\n",
    "\n",
    "            Parameters:\n",
    "                    audio_filename (str): Chaine de caract√®re correspondant au chemin d'acc√®s au fichier audio\n",
    "                    sampling_rate (int) : Nombre entier repr√©sentant la fr√©quence d'√©chantillonnage du fichier audio\n",
    "\n",
    "            Returns:\n",
    "                    noise_reduced_array (Numpy array) : Matrice de nombres repr√©sentant les √©chantillons du fichier audio apr√®s application de l'ensemble des pr√©-traitement\n",
    "                    \n",
    "\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    return noise_reduced_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b5fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e685234",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code permettant d'√©couter  et de visualiser la forme d'onde du flux audio r√©sultant de l'ensemble des pr√©-traitements</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67aa045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6172f68b",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: left; color:#20a08d; font-size: 25px\"><span>\n",
    "‚õèÔ∏è <strong>4. Extraction des caract√©ristiques</strong></span></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f7bd7",
   "metadata": {},
   "source": [
    "La sp√©cifit√© des donn√©es audio est qu'elles n√©cessitent souvent des descripteurs de niveau interm√©diaires pour √™tre utilis√©es dans les mod√®les de machine learning. Ces descripteurs s'appellent aussi des caract√©ristiques. Nous allons ici extraire ces caract√©ristiques des fichiers audio que nous avons pr√©-trait√©s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184043ca",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: left; color:#20a08d; font-size: 20px\"><span>‚õèÔ∏è <strong>4.1 Extraction des caract√©ristiques unitaire </strong></span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6316e6",
   "metadata": {},
   "source": [
    "Dans cette partie, nous d√©veloppons pas √† pas chacune des extractions de caract√©ristiques. Chaque extraction de caract√©ristique sera cod√©e dans une fonction et test√© sur la matrice numpy \"preprocessed_array\" obtenu en sortie de la fonction \"preprocessed_audio\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00429c7",
   "metadata": {},
   "source": [
    "Les caract√©ristiques √† extraire via librosa sont les suivantes:\n",
    "\n",
    "- Energy - Root Mean Square (RMS)\n",
    "- Zero Crossed Rate (ZCR)\n",
    "- Mel-Frequency Cepstral Coefficients (MFCCs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4ac3b1",
   "metadata": {},
   "source": [
    "Une des sp√©cificit√©s de l'audio est qu'aucune structuelle modulaire naturelle n'existe au sein d'un flux audio. \n",
    "\n",
    "Par exemple, au sein d'un flux vid√©o, il existe une structure modulaire naturelle qui est l'image. Une vid√©o de plusieurs heures peut ainsi √™tre d√©compos√©e en plusieurs images. Ainsi √† l'entr√©e des mod√®les de machine learning, il est possible d'utiliser une image ou un lot d'images.\n",
    "\n",
    "Mais qu'en est-il de l'audio ? Dans le cas de l'audio, il revient au datascientist de s√©quencer un flux audio en plusieurs s√©quences en utilisant des techniques de **fen√™trage (windowing)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a162d7",
   "metadata": {},
   "source": [
    "<img src=\"./assets/windowing.gif\" alt=\"Tech Logo\" align=\"center\" height=\"1280\" width=\"960\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28fca74",
   "metadata": {},
   "source": [
    "C'est √† partir de ces s√©quences fen√™tr√©es que seront extraites les caract√©ristiques √©voqu√©es ci-dessus.\n",
    "\n",
    "Fen√™trer revient donc √† d√©placer une fen√™tre glissante d'une certaine largeur avec un pas de d√©placement donn√©. La largeur de la fen√™tre s'appelle **window_length** et le pas de d√©placement s'appelle le **hop**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dda214",
   "metadata": {},
   "source": [
    "<img src=\"./assets/windowing.png\" alt=\"Tech Logo\" align=\"center\" height=\"1280\" width=\"960\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d988e7",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/68214065/is-my-output-of-librosa-mfcc-correct-i-think-i-get-the-wrong-number-of-frames-w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb07bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_LENGTH = 2048\n",
    "HOP_LENGTH = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ef9c1b",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#7a0f43\"><span>‚ùì Avec une taille de fen√™tre de <strong>FRAME_LENGTH</strong> et un pas de d√©placement de <strong>HOP_LENGTH</strong>, en combien de fen√™tres seront d√©coup√©es les fichiers ayant 96000 √©chantillons ?</span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee3f970",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81f511af",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: left; color:#20a08d; font-size: 15px\"><span>‚õèÔ∏è <strong>4.1.1 Extraction de l'Energy Root Mean Square (RMS)</strong></span></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130cfd4d",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code dans la fonction  <strong>get_energy_rms</strong> permettant d'extraire l'energy RMS d'une matrice d'√©chantillons, puis appelez cette fonction sur la matrice d'√©chantillons audio pr√©-trait√©s <strong>preprocessed_array</strong>. Attention √† l'utilisation de l'argument <strong>\"center\"</strong></span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a6eb8",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#ec8f1a\"><span>üìö  librosa.feature.rms : </span> <a href=\"https://librosa.org/doc/main/generated/librosa.feature.rms.html\">https://librosa.org/doc/main/generated/librosa.feature.rms.html</a></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2d98d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.feature import rms\n",
    "\n",
    "def get_energy_rms(audio_array, frame_length, hop_length):\n",
    "    \n",
    "    '''\n",
    "    Fonction permettant d'extraire d'une matrice d'√©chantillons audio l'energy RMS d'un flux audio\n",
    "\n",
    "            Parameters:\n",
    "                    audio_array (Numpy array): Matrice de nombres repr√©sentant les √©chantillons audio du fichier audio\n",
    "                    frame_length (int): Valeur enti√®re repr√©sentant la taille de fen√™tre pour le fen√™trage\n",
    "                    hop_length(int) : Valeur enti√®re repr√©sentant la taille du pas de d√©placement pour le fen√™trage\n",
    "\n",
    "\n",
    "            Returns:\n",
    "                    feature_rms (Numpy array): Matrice de nombres repr√©sentant l'energy rms\n",
    "                    \n",
    "\n",
    "    '''\n",
    "        \n",
    "    return feature_rms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af160f94",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code permettant d'afficher les dimensions de la matrice de caract√©ristiques r√©sultante</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3448587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "833b668b",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#7a0f43\"><span>‚ùì A quoi correspondent ces dimensions ?</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce00632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c598e9e4",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: left; color:#20a08d; font-size: 15px\"><span>‚õèÔ∏è <strong>4.1.2 Extraction du Zero Crossing Rate (ZCR)</strong></span></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0664a92",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code dans la fonction  <strong>get_zcr</strong> permettant d'extraire le zero crossing rate d'une matrice d'√©chantillons audio, puis appelez cette fonction sur la matrice d'√©chantillons audio pr√©-trait√©s<strong>preprocessed_array</strong></span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e52f2e",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#ec8f1a\"><span>üìö  librosa.feature.zero_crossing_rate : </span> <a href=\"http://librosa.org/doc/main/generated/librosa.feature.zero_crossing_rate.html\">http://librosa.org/doc/main/generated/librosa.feature.zero_crossing_rate.html</a></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.feature import zero_crossing_rate\n",
    "\n",
    "def get_zcr(audio_array, frame_length, hop_length):\n",
    "    \n",
    "    '''\n",
    "    Fonction permettant d'extraire d'une matrice d'√©chantillons audio le ZCR d'un flux audio\n",
    "\n",
    "            Parameters:\n",
    "                    audio_array (Numpy array): Matrice de nombres repr√©sentant les √©chantillons audio du fichier audio\n",
    "                    frame_length (int): Valeur enti√®re repr√©sentant la taille de fen√™tre pour le fen√™trage\n",
    "                    hop_length(int) : Valeur enti√®re repr√©sentant la taille du pas de d√©placement pour le fen√™trage\n",
    "\n",
    "\n",
    "            Returns:\n",
    "                    feature_zcr (Numpy array): Matrice de nombres repr√©sentant le ZCR\n",
    "                    \n",
    "\n",
    "    '''\n",
    "        \n",
    "    return feature_zcr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d138a6",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code permettant d'afficher les dimensions de la matrice de caract√©ristiques r√©sultante</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e28fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27248650",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#7a0f43\"><span>‚ùì A quoi correspondent ces dimensions ?</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb1731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18895150",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: left; color:#20a08d; font-size: 15px\"><span>‚õèÔ∏è <strong>4.1.3 Extraction des coefficients MFCC</strong></span></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5affe1a9",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code dans la fonction  <strong>get_mfcc</strong> permettant d'extraire les coefficients MFCC d'une matrice d'√©chantillons audio, puis appelez cette fonction sur la matrice d'√©chantillons audio pr√©-trait√©s<strong>preprocessed_array</strong>. Utilisez 13 coefficients MFCC par fen√™tre</span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35db4a68",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#ec8f1a\"><span>üìö  librosa.feature.mfcc : </span> <a href=\"https://librosa.org/doc/main/generated/librosa.feature.mfcc.html\">https://librosa.org/doc/main/generated/librosa.feature.mfcc.html</a></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601f25ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.feature import mfcc\n",
    "\n",
    "def get_mfcc(audio_array, hop_length, sampling_rate):\n",
    "    \n",
    "    '''\n",
    "    Fonction permettant d'extraire d'une matrice d'√©chantillons audio les coefficients MFCC d'un flux audio\n",
    "\n",
    "            Parameters:\n",
    "                    audio_array (Numpy array): Matrice de nombres repr√©sentant les √©chantillons audio du fichier audio\n",
    "                    sampling_rate (int) : Nombre entier repr√©sentant la fr√©quence d'√©chantillonnage du fichier audio\n",
    "                    hop_length (int) : Valeur enti√®re repr√©sentant la taille du pas de d√©placement pour le fen√™trage\n",
    "\n",
    "\n",
    "            Returns:\n",
    "                    feature_mfcc (Numpy array): Matrice de nombres repr√©sentant les coefficients MFCC\n",
    "                    \n",
    "\n",
    "    '''\n",
    "        \n",
    "    return feature_mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3000793",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code permettant d'afficher les dimensions de la matrice de caract√©ristiques r√©sultante</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9040bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2dd7b0b",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#7a0f43\"><span>‚ùì A quoi correspondent ces dimensions ?</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e365c92d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fe64f83",
   "metadata": {},
   "source": [
    "Utilisez le code ci-dessous pour afficher les coefficients MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e141d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "librosa.display.specshow(mfccs, sr=SR_RAVDESS, x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c516210",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: left; color:#20a08d; font-size: 20px\"><span>‚õèÔ∏è <strong>4.2 Extraction des caract√©ristiques unifi√©e </strong></span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578675e0",
   "metadata": {},
   "source": [
    "Ici, nous rassemblons l'ensemble des traitements d'extractions de caract√©ristiques en une seule fonction, puis nous concat√©nons l'ensemble des caract√©ristiques RMS, ZCR, MFCC en une seule matrice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b673a8",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code dans la fonction  <strong>extract_features_audio</strong> permettant d'extraire d'une matrice d'√©chantillons audio l'ensemble des caract√©ristiques et des concat√©ner en une seule, puis appelez cette fonction sur la matrice d'√©chantillons audio pr√©-trait√©s <strong>preprocessed_array</strong>.</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e42bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_audio(audio_array, sampling_rate, frame_length, hop_length):\n",
    "    \n",
    "    '''\n",
    "    Fonction permettant d'extraire d'une matrice d'√©chantillons audio l'ensemble des caract√©ristiques et des concat√©ner en une seule\n",
    "\n",
    "            Parameters:\n",
    "                    audio_array (Numpy array): Matrice de nombres repr√©sentant les √©chantillons audio du fichier audio\n",
    "                    sampling_rate (int) : Nombre entier repr√©sentant la fr√©quence d'√©chantillonnage du fichier audio\n",
    "                    frame_length (int): Valeur enti√®re repr√©sentant la taille de fen√™tre pour le fen√™trage\n",
    "                    hop_length (int) : Valeur enti√®re repr√©sentant la taille du pas de d√©placement pour le fen√™trage\n",
    "\n",
    "\n",
    "            Returns:\n",
    "                    features_all (Numpy array): Matrice de nombres repr√©sentant l'ensemble des caract√©ristiques concat√©n√©es\n",
    "                    \n",
    "\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    return features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951da3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e7ca3fc",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: left; color:#20a08d; font-size: 25px\"><span>\n",
    "üóÑÔ∏è <strong>5. Application de la chaine compl√®te de traitement des donn√©es: pr√©-traitement + extraction de caract√©ristiques</strong></span></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bedf6b1",
   "metadata": {},
   "source": [
    "Ici, nous rassemblons en une seule fonction l'ensemble des traitements : pr√©-traitement et extraction des caract√©ristiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63397fd7",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: left; color:#20a08d; font-size: 20px\"><span>üóÑÔ∏è <strong>5.1 Traitement unitaire </strong></span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c1192",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code dans la fonction  <strong>process_data</strong> permettant de r√©aliser sur un fichier audio l'ensemble des trait√©ments de pr√©paration des donn√©es (pr√©-traitement + extraction de caract√©ristiques), puis appelez cette fonction sur le fichier exemple <strong>RAVDESS_FILE_EXAMPLE</strong>.</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee0e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(audio_filename, hop_length, frame_length, sampling_rate):\n",
    "    \n",
    "    '''\n",
    "    Fonction permettant de r√©aliser sur un fichier audio l'ensemble des trait√©ments de pr√©paration des donn√©es : pr√©-traitement + extraction de caract√©ristiques\n",
    "\n",
    "            Parameters:\n",
    "                    audio_filename (str): Chaine de caract√®re correspondant au chemin d'acc√®s au fichier audio\n",
    "                    sampling_rate (int) : Nombre entier repr√©sentant la fr√©quence d'√©chantillonnage du fichier audio\n",
    "                    frame_length (int): Valeur enti√®re repr√©sentant la taille de fen√™tre pour le fen√™trage\n",
    "                    hop_length (int) : Valeur enti√®re repr√©sentant la taille du pas de d√©placement pour le fen√™trage\n",
    "\n",
    "\n",
    "            Returns:\n",
    "                    preprocessed_array (Numpy array): Matrice de nombres repr√©sentant les √©chantillons audio apr√®s pr√©-traitement (normalisation, ...)\n",
    "                    features (Numpy array): Matrice de nombres repr√©sentant l'ensemble des caract√©ristiques concat√©n√©es\n",
    "\n",
    "\n",
    "    '''\n",
    "        \n",
    "    \n",
    "    return preprocessed_array, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923dedad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "223f082e",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: left; color:#20a08d; font-size: 20px\"><span>üóÑÔ∏è <strong>5.2 D√©termination de la classe d'appartenance </strong></span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0175e89b",
   "metadata": {},
   "source": [
    "Le but ici est de d√©velopper une fonction permettante d'extraire la classe d'appartenance c'est-√†-dire l'√©motion exprim√©e dans un fichier audio √† partir des donn√©es indiqu√©es dans le nom de fichier.\n",
    "\n",
    "Par convention :\n",
    "- La classe **\"neutre\"** sera encod√©e par le nombre entier **0**\n",
    "- La classe **\"joie\"** sera encod√©e par le nombre entier **1**\n",
    "- La classe **\"tristesse\"** sera encod√©e par le nombre entier **2**\n",
    "- La classe **\"colere\"** sera encod√©e par le nombre entier **3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e29ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTION_DICT = {0:\"neutre\", 1:\"joie\", 2:\"tristesse\", 3:\"colere\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2319c77",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code dans la fonction  <strong>get_ravdess_label</strong> permettant de d√©terminer la classe d'√©motion exprim√©e dans un fichier audio RAVDESS √† partir de son nom, puis appelez cette fonction sur les fichiers exemple <strong>RAVDESS_FILE_EXAMPLE_1</strong>, <strong>RAVDESS_FILE_EXAMPLE_2</strong>, <strong>RAVDESS_FILE_EXAMPLE_3</strong>, <strong>RAVDESS_FILE_EXAMPLE_4</strong>.</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0155dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ravdess_label(audio_filename):\n",
    "    \n",
    "    '''\n",
    "    Fonction permettant de d√©terminer la classe d'√©motion exprim√©e dans un fichier audio RAVDESS √† partir de son nom\n",
    "\n",
    "            Parameters:\n",
    "                    audio_filename (str): Chaine de caract√®re correspondant au chemin d'acc√®s au fichier audio\n",
    "\n",
    "            Returns:\n",
    "                    - (int): Nombre entier repr√©sentant la classe de l'√©motion\n",
    "\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9200ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAVDESS_FILE_EXAMPLE_1 = \"./dataset/ravdess/03-01-04-01-02-02-22.wav\"\n",
    "RAVDESS_FILE_EXAMPLE_2 = \"./dataset/ravdess/03-01-05-01-02-01-19.wav\"\n",
    "RAVDESS_FILE_EXAMPLE_3 = \"./dataset/ravdess/03-01-03-01-02-02-11.wav\"\n",
    "RAVDESS_FILE_EXAMPLE_4 = \"./dataset/ravdess/03-01-01-01-01-02-20.wav\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a828938e",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code dans la fonction  <strong>get_tess_label</strong> permettant de d√©terminer la classe d'√©motion exprim√©e dans un fichier audio TESS √† partir de son nom, puis appelez cette fonction sur les fichiers exemple <strong>TESS_FILE_EXAMPLE_1</strong>, <strong>TESS_FILE_EXAMPLE_2</strong>, <strong>TESS_FILE_EXAMPLE_3</strong>, <strong>TESS_FILE_EXAMPLE_4</strong>.</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae3733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tess_label(audio_filename):\n",
    "    \n",
    "    '''\n",
    "    Fonction permettant de d√©terminer la classe d'√©motion exprim√©e dans un fichier audio TESS √† partir de son nom\n",
    "\n",
    "            Parameters:\n",
    "                    audio_filename (str): Chaine de caract√®re correspondant au chemin d'acc√®s au fichier audio\n",
    "\n",
    "            Returns:\n",
    "                    - (int): Nombre entier repr√©sentant la classe de l'√©motion\n",
    "\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f02b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESS_FILE_EXAMPLE_1 = \"./dataset/tess/OAF_lose_sad.wav\"\n",
    "TESS_FILE_EXAMPLE_2 = \"./dataset/tess/YAF_mop_happy.wav\"\n",
    "TESS_FILE_EXAMPLE_3 = \"./dataset/tess/OAF_turn_neutral.wav\"\n",
    "TESS_FILE_EXAMPLE_4 = \"./dataset/tess/YAF_met_angry.wav\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276880bd",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: left; color:#20a08d; font-size: 20px\"><span>üóÑÔ∏è <strong>5.3 Traitement de l'ensemble des fichiers audio </strong></span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04807c51",
   "metadata": {},
   "source": [
    "Nous disposons d√©sormais de tous les √©l√©ments permettant d'obtenir les donn√©es d'entrainement (caract√©ristiques) et les labels associ√©s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2fc5c9",
   "metadata": {},
   "source": [
    "Puisque nous utilisons de l'apprentissage supervis√©, il nous faut cr√©er un tableau de donn√©es (caract√©ristisques) et un tableau de labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb88c4d4",
   "metadata": {},
   "source": [
    "<img src=\"./assets/processing.jpg\" alt=\"Tech Logo\" align=\"center\" height=\"800\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039dab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = \"./dataset\"\n",
    "features_list = list()\n",
    "labels_list = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bb60bf",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#131fcf\"><span>üñ•Ô∏è  Ecrivez le code permettant de parcourir les fichiers audio RAVDESS et TESS, d'en d√©terminer la fr√©quence d'√©chantillonnage, de calculer la matrice de caract√©ristiques du fichier audio, d'extraire la classe d'appartenance du fichier audio, puis ins√©rer la matrice de caract√©ristiques et la classe d'appartenance respectivement dans les listes <strong>features_list</strong> et <strong>labels_list</strong>. Convertissez enfin les listes <strong>features_list</strong> et <strong>labels_list</strong> en matrice numpy array <strong>features_array</strong> et <strong>labels_array</strong></span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ac2907",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left; font-size: 16px; color:#ec8f1a\"><span>üìö  \n",
    "Iterate over files in a directory in Python\n",
    " : </span> <a href=\"https://www.techiedelight.com/iterate-over-files-directory-python/\">https://www.techiedelight.com/iterate-over-files-directory-python/</a></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6be6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.core import get_samplerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_array.shape)\n",
    "print(labels_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d40fb2",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: left; color:#20a08d; font-size: 25px\"><span>\n",
    "üìº <strong>6. Sauvegarde des donn√©es d'entrainement et des labels</strong></span></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44364ed6",
   "metadata": {},
   "source": [
    "Nous allons ici sauvegarder sur notre disque les donn√©es d'entrainement et les labels correspondant aux matrices que nous avons g√©n√©r√©es.\n",
    "\n",
    "Pour ce faire, nous utiliserons la librairie pickle qui permet d'enregistrer des donn√©es en gardant leur structure d'origine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72087c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./features.array', 'wb') as features:\n",
    "    pickle.dump(features_array, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ae957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./labels.array', 'wb') as labels:\n",
    "    pickle.dump(labels_array, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfa8ca3",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: left; color:#20a08d; font-size: 25px\"><span>\n",
    "üìº <strong>7. Sauvegarde des fonctions de pr√©-traitement en script Python</strong></span></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b171f5",
   "metadata": {},
   "source": [
    "Copier ci-dessous le contenu des fonctions ci-dessous:\n",
    "- normalize_audio\n",
    "- remove_silence_from_audio\n",
    "- length_equalization_audio\n",
    "- noise_reduction_from_audio\n",
    "- preprocess_audio\n",
    "- get_energy_rms()\n",
    "- get_zcr()\n",
    "- get_mfcc()\n",
    "- extract_features_audio()\n",
    "- process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fbaa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../3.RealtimeEvaluation/preprocessing.py\n",
    "MAX_SAMPLES = 96000\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from pydub import AudioSegment, effects\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile\n",
    "import noisereduce as nr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from librosa import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3460f696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
